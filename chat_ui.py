import os
import gradio as gr
from download_model import LocalLLM

class ChatUI:
    def __init__(self):
        self.llm = None
        self.model_loaded = False
        
    def get_available_models(self):
        """è·å–å·²ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨"""
        models_dir = "./models"
        if not os.path.exists(models_dir):
            return []
        
        models = []
        for item in os.listdir(models_dir):
            model_path = os.path.join(models_dir, item)
            if os.path.isdir(model_path):
                models.append(os.path.basename(model_path))
        return models
    
    def load_model(self, model_name, progress=gr.Progress()):
        """åŠ è½½é€‰å®šçš„æ¨¡å‹"""
        if not model_name:
            return "è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹"
        
        model_path = os.path.join("./models", model_name)
        if not os.path.exists(model_path):
            return f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}"
        
        progress(0.1, desc="åˆå§‹åŒ–æ¨¡å‹...")
        self.llm = LocalLLM(model_path)
        
        progress(0.5, desc="åŠ è½½æ¨¡å‹æ–‡ä»¶...")
        success = self.llm.load_model()
        
        if success:
            self.model_loaded = True
            progress(1.0, desc="åŠ è½½å®Œæˆï¼")
            return f"æ¨¡å‹ {model_name} åŠ è½½æˆåŠŸï¼"
        else:
            self.model_loaded = False
            return f"æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥"
    
    def chat_response(self, message, history, temperature, max_length):
        """ç”ŸæˆèŠå¤©å›å¤"""
        if not self.model_loaded or self.llm is None:
            return history + [("è¯·å…ˆåŠ è½½æ¨¡å‹", "")]
        
        if not message.strip():
            return history + [("", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ¶ˆæ¯")]
        
        # ç”Ÿæˆå›å¤
        response = self.llm.generate_response(
            message, 
            max_length=max_length, 
            temperature=temperature
        )
        
        # æ›´æ–°å†å²è®°å½•
        history.append((message, response))
        return history
    
    def clear_chat(self):
        """æ¸…ç©ºèŠå¤©è®°å½•"""
        return []

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    chat_ui = ChatUI()
    
    with gr.Blocks(title="æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹å¯¹è¯", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸ¤– æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹å¯¹è¯ç³»ç»Ÿ")
        gr.Markdown("åŸºäºQwen2æˆ–DeepSeekçš„æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ")
        
        with gr.Row():
            with gr.Column(scale=2):
                # æ¨¡å‹é€‰æ‹©å’ŒåŠ è½½
                with gr.Group():
                    gr.Markdown("### ğŸ“‚ æ¨¡å‹ç®¡ç†")
                    model_dropdown = gr.Dropdown(
                        choices=chat_ui.get_available_models(),
                        label="é€‰æ‹©æ¨¡å‹",
                        info="è¯·å…ˆä¸‹è½½æ¨¡å‹"
                    )
                    refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", size="sm")
                    load_btn = gr.Button("ğŸš€ åŠ è½½æ¨¡å‹", variant="primary")
                    load_status = gr.Textbox(
                        label="åŠ è½½çŠ¶æ€",
                        interactive=False,
                        placeholder="è¯·é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹"
                    )
                
                # å‚æ•°è®¾ç½®
                with gr.Group():
                    gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
                    temperature = gr.Slider(
                        minimum=0.1, 
                        maximum=2.0, 
                        value=0.7, 
                        step=0.1,
                        label="Temperature (åˆ›é€ æ€§)",
                        info="å€¼è¶Šé«˜å›å¤è¶Šæœ‰åˆ›é€ æ€§"
                    )
                    max_length = gr.Slider(
                        minimum=128, 
                        maximum=4096, 
                        value=2048, 
                        step=128,
                        label="æœ€å¤§å›å¤é•¿åº¦",
                        info="ç”Ÿæˆå›å¤çš„æœ€å¤§tokenæ•°"
                    )
            
            with gr.Column(scale=3):
                # èŠå¤©ç•Œé¢
                gr.Markdown("### ğŸ’¬ å¯¹è¯åŒºåŸŸ")
                chatbot = gr.Chatbot(
                    height=500,
                    show_label=False,
                    container=True,
                    bubble_full_width=False
                )
                
                with gr.Row():
                    msg_input = gr.Textbox(
                        placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„æ¶ˆæ¯...",
                        show_label=False,
                        scale=4,
                        container=False
                    )
                    send_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary", scale=1)
                
                with gr.Row():
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", variant="secondary")
                    stop_btn = gr.Button("â¹ï¸ åœæ­¢ç”Ÿæˆ", variant="stop")
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“‹ ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            **ä½¿ç”¨æ­¥éª¤:**
            1. ç¡®ä¿å·²è¿è¡Œ `python download_model.py` ä¸‹è½½æ¨¡å‹
            2. åœ¨æ¨¡å‹ç®¡ç†åŒºåŸŸé€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹
            3. ç‚¹å‡»"åŠ è½½æ¨¡å‹"æŒ‰é’®ï¼Œç­‰å¾…åŠ è½½å®Œæˆ
            4. åœ¨å¯¹è¯åŒºåŸŸè¾“å…¥æ¶ˆæ¯å¹¶å‘é€
            
            **å‚æ•°è¯´æ˜:**
            - **Temperature**: æ§åˆ¶å›å¤çš„éšæœºæ€§å’Œåˆ›é€ æ€§ï¼Œ0.1-2.0
            - **æœ€å¤§å›å¤é•¿åº¦**: é™åˆ¶æ¯æ¬¡å›å¤çš„æœ€å¤§é•¿åº¦
            
            **æ³¨æ„äº‹é¡¹:**
            - é¦–æ¬¡åŠ è½½æ¨¡å‹éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
            - å»ºè®®æ ¹æ®æ˜¾å¡æ€§èƒ½è°ƒæ•´å‚æ•°
            - 4060æ˜¾å¡å»ºè®®ä½¿ç”¨4bité‡åŒ–é™ä½æ˜¾å­˜å ç”¨
            """)
        
        # äº‹ä»¶ç»‘å®š
        refresh_btn.click(
            fn=lambda: gr.Dropdown(choices=chat_ui.get_available_models()),
            outputs=model_dropdown
        )
        
        load_btn.click(
            fn=chat_ui.load_model,
            inputs=model_dropdown,
            outputs=load_status
        )
        
        msg_input.submit(
            fn=chat_ui.chat_response,
            inputs=[msg_input, chatbot, temperature, max_length],
            outputs=chatbot
        ).then(
            lambda: "",
            outputs=msg_input
        )
        
        send_btn.click(
            fn=chat_ui.chat_response,
            inputs=[msg_input, chatbot, temperature, max_length],
            outputs=chatbot
        ).then(
            lambda: "",
            outputs=msg_input
        )
        
        clear_btn.click(
            fn=chat_ui.clear_chat,
            outputs=chatbot
        )
    
    return interface

def main():
    """å¯åŠ¨Webç•Œé¢"""
    print("æ­£åœ¨å¯åŠ¨Webç•Œé¢...")
    interface = create_interface()
    
    # å¯åŠ¨æœåŠ¡å™¨
    interface.launch(
        server_name="127.0.0.1",
        server_port=7860,
        show_api=False,
        share=False,
        inbrowser=True
    )

if __name__ == "__main__":
    main()
